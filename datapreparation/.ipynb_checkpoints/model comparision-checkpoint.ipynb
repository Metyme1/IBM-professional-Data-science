{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b1c7f6-9e1f-4eb9-bb60-d724ac25482b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (2938, 22)\n",
      "\n",
      "Data types:\n",
      "Country                             object\n",
      "Year                                 int64\n",
      "Status                              object\n",
      "Life expectancy                    float64\n",
      "Adult Mortality                    float64\n",
      "infant deaths                        int64\n",
      "Alcohol                            float64\n",
      "percentage expenditure             float64\n",
      "Hepatitis B                        float64\n",
      "Measles                              int64\n",
      "BMI                                float64\n",
      "under-five deaths                    int64\n",
      "Polio                              float64\n",
      "Total expenditure                  float64\n",
      "Diphtheria                         float64\n",
      "HIV/AIDS                           float64\n",
      "GDP                                float64\n",
      "Population                         float64\n",
      "thinness  1-19 years               float64\n",
      "thinness 5-9 years                 float64\n",
      "Income composition of resources    float64\n",
      "Schooling                          float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "Country                              0\n",
      "Year                                 0\n",
      "Status                               0\n",
      "Life expectancy                     10\n",
      "Adult Mortality                     10\n",
      "infant deaths                        0\n",
      "Alcohol                            194\n",
      "percentage expenditure               0\n",
      "Hepatitis B                        553\n",
      "Measles                              0\n",
      "BMI                                 34\n",
      "under-five deaths                    0\n",
      "Polio                               19\n",
      "Total expenditure                  226\n",
      "Diphtheria                          19\n",
      "HIV/AIDS                             0\n",
      "GDP                                448\n",
      "Population                         652\n",
      "thinness  1-19 years                34\n",
      "thinness 5-9 years                  34\n",
      "Income composition of resources    167\n",
      "Schooling                          163\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor  # Regressor for continuous target\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load and clean column names\n",
    "df = pd.read_csv('Life Expectancy Data.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Check your data\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf55168-85b7-43d5-abc8-a146cc32d82f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Cabo Verde'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_13584\\3578756134.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m model_raw = RandomForestClassifier(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model_raw.fit(X_train, y_train)\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m y_pred_raw = model_raw.predict(X_test)\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    356\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m    358\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         X, y = validate_data(\n\u001b[32m    360\u001b[39m             self,\n\u001b[32m    361\u001b[39m             X,\n\u001b[32m    362\u001b[39m             y,\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Cabo Verde'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('Life Expectancy Data.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Separate target\n",
    "target = 'Life expectancy'\n",
    "y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "# ============================================\n",
    "# MINIMAL PROCESSING (Required for model to run)\n",
    "# ============================================\n",
    "\n",
    "# Drop rows where target is missing\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Handle categorical columns (required - model can't use text)\n",
    "X_minimal = X.copy()\n",
    "\n",
    "# Option 1: Drop text columns\n",
    "X_minimal = X_minimal.drop(['Country', 'Status'], axis=1)\n",
    "\n",
    "# Fill missing values with median (required - model can't use NaN)\n",
    "X_minimal = X_minimal.fillna(X_minimal.median())\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_minimal, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# EXPERIMENT 1: Without Extra Preprocessing\n",
    "# ============================================\n",
    "model_raw = RandomForestRegressor(random_state=42)\n",
    "model_raw.fit(X_train, y_train)\n",
    "y_pred_raw = model_raw.predict(X_test)\n",
    "\n",
    "r2_raw = r2_score(y_test, y_pred_raw)\n",
    "rmse_raw = np.sqrt(mean_squared_error(y_test, y_pred_raw))\n",
    "print(f\"WITHOUT extra preprocessing:\")\n",
    "print(f\"  R² Score: {r2_raw:.4f}\")\n",
    "print(f\"  RMSE:     {rmse_raw:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# EXPERIMENT 2: With Full Preprocessing\n",
    "# ============================================\n",
    "X_processed = X.copy()\n",
    "\n",
    "# Encode categorical columns instead of dropping\n",
    "le_status = LabelEncoder()\n",
    "X_processed['Status'] = le_status.fit_transform(X_processed['Status'])\n",
    "\n",
    "# Drop Country (too many unique values) or encode it\n",
    "X_processed = X_processed.drop('Country', axis=1)\n",
    "\n",
    "# Fill missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_processed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_processed),\n",
    "    columns=X_processed.columns\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_processed)\n",
    "\n",
    "# Split (same random state!)\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model_processed = RandomForestRegressor(random_state=42)\n",
    "model_processed.fit(X_train_p, y_train_p)\n",
    "y_pred_processed = model_processed.predict(X_test_p)\n",
    "\n",
    "r2_processed = r2_score(y_test_p, y_pred_processed)\n",
    "rmse_processed = np.sqrt(mean_squared_error(y_test_p, y_pred_processed))\n",
    "print(f\"\\nWITH full preprocessing:\")\n",
    "print(f\"  R² Score: {r2_processed:.4f}\")\n",
    "print(f\"  RMSE:     {rmse_processed:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# COMPARISON\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"R² improvement:   {r2_processed - r2_raw:.4f}\")\n",
    "print(f\"RMSE improvement: {rmse_raw - rmse_processed:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c847c427-51b5-4be4-b0c5-ed93d57f2e24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, LabelEncoder\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train_processed = \u001b[43mX_train\u001b[49m.copy()\n\u001b[32m      5\u001b[39m X_test_processed = X_test.copy()\n\u001b[32m      8\u001b[39m imputer = SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m)  \n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_train_processed = X_train.copy()\n",
    "X_test_processed = X_test.copy()\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X_train_processed = imputer.fit_transform(X_train_processed)\n",
    "X_test_processed = imputer.transform(X_test_processed)  \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_processed = scaler.fit_transform(X_train_processed)\n",
    "X_test_processed = scaler.transform(X_test_processed)\n",
    "\n",
    "\n",
    "model_processed = RandomForestClassifier(random_state=42)\n",
    "model_processed.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "y_pred_processed = model_processed.predict(X_test_processed)\n",
    "accuracy_processed = accuracy_score(y_test, y_pred_processed)\n",
    "print(f\"Accuracy WITH preprocessing: {accuracy_processed:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad2a45-7d97-48bf-9f5e-118d3841a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPERIMENT RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Without Preprocessing: {accuracy_raw:.4f}\")\n",
    "print(f\"With Preprocessing:    {accuracy_processed:.4f}\")\n",
    "print(f\"Improvement:           {accuracy_processed - accuracy_raw:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131dd2c0-63c0-4df9-829b-89a575ba90ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a91b751-85bb-4e39-9291-c4ff943fadf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Country', 'Year', 'Status', 'Life expectancy ', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years', ' thinness 5-9 years', 'Income composition of resources', 'Schooling']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a4958-c82e-4803-a48e-9a7ceebdeae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
